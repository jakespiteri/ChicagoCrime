% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LR_OOP.R
\name{cv.lr}
\alias{cv.lr}
\title{Cross-Validation of Logistic Regression Model}
\usage{
cv.lr(lrfit, metric = "mse", leave_out = nrow(lrfit$data)/10,
  verbose = TRUE, seed = 1)
}
\arguments{
\item{lrfit}{an object of class "\code{lr}", the output to \code{\link{lr}}}

\item{metric}{which metric to calculate, one of "mse", "auc" or "both". See 'Details'.}

\item{leave_out}{number of points to leave out for cross-validation.}

\item{verbose}{logical; whether to print information about number of iterations completed.}

\item{seed}{optional; number to be passed to \code{\link[base]{set.seed}} before shuffling the data set}
}
\value{
error value or vector consisting of the average of the chosen \code{metric}
}
\description{
Implementation of cross-validation for a \code{\link{lr}} object, calculation of error across
a number of subsets of the inputted data set.
}
\details{
\eqn{k}-fold cross-validation, where \eqn{k} is the input to the \code{leave_out} argument.
This can be used to judge the out-of-sample predictive power of the model by subsetting the original
data set into two partitions; fitting the model for the (usually larger) one, and testing the
predictions of that model on the (usually smaller) partition. The position of the \eqn{k}
points separated from the data set are selected uniformly at random.

The error metrics available are that of mean squared error, AUC, or log score; selected by the \code{metric}
argument being one of "mse", "auc", "log" or "all". See \code{\link{roc.lr}} for details on AUC.
If \code{metric} is "all", then a vector will be output containing all three metrics.

Note that the output from \code{metric = "auc"} has non-deterministic elements due to the shuffling
of the data set. To mitigate this, include a number to the \code{seed} argument.
}
